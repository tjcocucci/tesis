\chapter{Tratamiento de errores} \label{chp:error_treatment}

\section{Error observacional y de modelo} \label{sec:model_obs_error}

Más allá de los desafíos y dificultades de implementación de las técnicas de asimilación de datos discutidas en el capítulo anterior, la performance de éstas depende crucialmente de la especificación del error de modelo y el observacional. Tanto la predicción de las variables de estado en el tiempo como el proceso observacional tienen fuentes de incerteza \citep{Tandeo2020,Dee1995,Dee1999}. De hecho, las metodologías de asimilación de datos hacen uso de nuestro conocimiento sobre estas incertidumbres para ponderar entre la información que brinda el pronóstico producido por el modelo y la observación. Veremos que una representación incorrecta de estos errores, y en particular de la razón entre estos, puede dar lugar a un exceso de confianza en los pronósticos o en las observaciones. Esto puede ocasionar que se degrade la calidad de las estimaciones de las distribuciones filtrantes y potencialmente que el filtro se desicronice de la trayectoria subyacente que se intenta inferir.

Las variables de estado evolucionan en el tiempo mediante la aplicación del modelo $\mathcal{M}_t$, ecuación \ref{eq:transition}, el cual se diseña para representar en forma simplificada la dinámica del proceso subyacente. Por supuesto, estos modelos para sistemas complejos constituyen una representación imperfecta de la realidad que buscan describir. En lo que llamamos error de modelo, no sólo incluímos este error de representatividad sino también los provenientes de aproximaciones para simplificar el cómputo, errores numéricos y posiblemente la incerteza proveniente del desconocimiento de valores exactos de la parametrización de $\mathcal{M}_t$. Llamaremos laxamente $\v Q$ al error de modelo usando la notación en \ref{eq:kf_forward} que corresponde a la habitual hipótesis en que lo consideremos aditivo, Gaussiano e insesgado. En forma estricta $\v Q$ es la covarianza de la distribución de transición, la cual bajo las hipótesis mencionadas, la determina de manera única. Por otro lado, el error observacional comprende al error de representatividad del operador $\mathcal{H}_t$, las imperfecciones en su especificación y las incertezas intrínsecas de los instrumentos de medición. Análogamente al error de modelo usaremos $\v R$ para referirnos al error observacional. También asumimos para este que es aditivo, Gaussiano e insesgado. Tenemos entonces que $\v Q$ y $\v R$ acumulan el error de diversas fuentes de incerteza y que además en ciertos casos, como el conocimiento incompleto sobre los fenómenos que modelamos, no disponemos de una cuantificación de estas incertidumbres.

Para ilustrar la importancia de especificar correctamente $\v Q$ y $\v R$ consideremos que tenemos el modelo del oscilador armónico introducido en \ref{sec:kf}, totalmente observado con error de modelo $\v Q = \sigma_Q^2 \v I$ y error observacional $\v R = \sigma_R^2 \v I$. Con esta configuración generamos una trayectoria real y sus respectivas observaciones. Luego asimilamos estas observaciones con el EnKF para recuperar el estado real, pero para ello utilizaremos distintos valores de $\sigma_Q^2$ y $\sigma_R^2$. Para evaluar la performance del EnKF en cada repetición, consideraremos dos métricas: la raíz del error cuadrático medio (RMSE) y la cobertura. El RMSE nos informa cuan cerca esta la media de la estimación de la trayectoria real. Por otro lado la cobertura indica en que porcentaje la trayectoria real está incluída en las correspondientes bandas de confianza. Consideraremos un nivel de confianza del 95\% por lo que valores mayores a este indican una sobreestimación de la dispersión de la distribución filtrante mientras que valores menores corresponden a una subestimación. En la figura \ref{fig:QR_performance_trajectories} podemos ver las estimaciones del EnKF para distintas configuraciones de $\v Q$ y $\v R$ (los valores reales están indicados con $\v Q_t$ y $\v R_t$) junto con las métricas obtenidas. En el caso en que se utiliza un $\v Q < \v Q_t$ y un $\v R > \v R_t$ se tiene que la trayectoria estimada es suave, porque al subestimar el error de modelo y sobreestimar el observacional se produce el efecto de que el sistema de asimilación considera más precisos a los pronósticos que a las observaciones y por lo tanto las trayectorias prácticamente no son corregidas y se asemejan a las del modelo. Este efecto se puede ver como un subajuste (\textit{underfit}) a las observaciones y resulta en un RMSE alto; el comportamiento del filtro en esta situación en que las trayectorias prácticamente ignoran a las observaciones suele llamarse divergencia del filtro. En el caso contrario, en que $\v Q > \v Q_t$ y $\v R < \v R_t$, se tiene un efecto de sobreajuste (\textit{overfit}) a las observaciones puesto que se está subestimando su error y por lo tanto las estimaciones se acercan demasiado a ellas dando lugar a trayectorias mucho menos suaves. El caso en el que se utilicen errores de modelo y observacional menores a los reales se tiene que el RMSE es pequeño pero evidentemente la dispersión está subestimada. Por otro lado si ambos errores son mayores que los verdaderos se tiene que la dispersión está sobreestimada. El caso en que se usan los errores reales corresponde entonces a una solución de compromiso entre una correcta cobertura y un RMSE no demasiado grande. Podemos ver en los mapas de calor de la figura \ref{fig:QR_heatmap} que es importante la razón entre $\v Q$ y $\v R$: mientras este cociente es similar al cociente real entre $\v Q_t$ y $\v R_t$ se tendrá una estimación aproximadamente buena de la media, es decir bajo RMSE. Sin embargo la subestimación conjunta de ambos errores (manteniendo la razón entre ellos) produce una mala cobertura (subestimación de la dispersión) y lo contrario sucede con la sobreestimación conjunta. También se hace evidente que en la zona de \textit{overfit} (esquina inferior izquierda del panel de la derecha) se produce menos RMSE que la zona de \textit{underfit} (esquina superior derecha). Esto es debido a que cuando hay \textit{overfit} las estimaciiones tienden a interpolar las observaciones y por lo tanto se mantienen relativamente esn sincronía con las trayectorias reales pero en el caso de \textit{underfit} las estimaciones no se ven influenciadas por las obsevaciones y por lo tanto resultan también independientes de las trayectorias reales. Este análisis, desarrollado en mayor profundidad en \cite{Tandeo2020}, pone en evidencia la importancia de la estimación de estas incertezas, en particular de su especificación conjunta, para maximizar la performance de las técnicas de asimilación de datos.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{QR_performance_trajectories.eps}
    \caption{Posición $x$ del oscilador armónico y estimaciones del EnKF para diferentes configuraciones de $\v Q$ y $\v R$.}
    \label{fig:QR_performance_trajectories}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{QR_heatmap.eps}
    \caption{RMSE y cobertura producidas por el EnKF en la estimación del oscilador armónico para para diferentes configuraciones de $\v Q$ y $\v R$. Los valores reales se indican con un recuadro azul. La barra de colores para la cobertura tiene un escalado lineal para que el centro (color blanco) esté en el valor ópimo de cobertura de 95\%.}
    \label{fig:QR_heatmap}
\end{figure}

Como hemos visto en la Sección \ref{sec:enkf}, los métodos basados en ensambles tienen tendencia a colapsar debido a errores de muestreo. El error de modelo cobra una relevancia especial pues está asociada a la dispersión de las partículas del pronóstico y por lo tanto es importante especificarlo correctamente para un buen desempeño del sistema de asimilación. Por su parte, en los filtros de partículas, el error de modelo se relaciona a la incerteza de cada partícula. Muchos filtros de partículas modernos buscan mejorar el muestreo llevando a las partículas a regiones de alta verosimilitud como por ejemplo los filtros de partículas implícitos \citep{Chorin2009, Atkins2013, Zhu2016}, los filtros de flujos de partículas temperados \citep{Daum2009} o el filtro de partículas con mapeo variacional \citep{Pulido2019}. Estos suponen el conocimiento de $\v Q$ y por lo tanto se hace relevante poder acoplarlos con una metodología de estimación de dichos errores.

Se han desarrollado una gran cantidad de métodos para estimar estos errores. En \cite{Stroud2018} se apunta a maximizar la verosimilitud de las innovaciones (la diferencia entre la observación y el pronóstico mapeado al espacio observacional) utilizando inferencia Bayesiana. En otros trabajos se utilizan las covarianzas cruzadas entre innovaciones sucesivas para producir estimaciones de $\v Q$ y $\v R$ (Ver por ejemplo el trabajo seminal de \cite{Mehra1970} y una adaptación moderna basada en esta en \cite{Berry2013}). En el trabajo de \cite{Desroziers2005} se definen estadísticos de diagnóstico basados en las innovaciones que pueden ser utilizados para obtener coeficientes de inflación adaptativos \citep{Li2009}. Notemos que la inflación puede ser vista como un método de estimación del error de modelo puesto que da cuenta de la necesidad de ajustar la incertidumbre de los pronósticos. Sin embargo hay que notar que, por ser multiplicativa, amplificará la covarianza muestral sobretodo en las direcciones en que el pronóstico ya tenga mayor dispersión \citep{Hamill2005}. Otra aproximación al problema, sobre la que nos centraremos aquí, es la maximización de la verosimilitud total a través del algoritmo EM (\textit{expectation-maximization}, \cite{Dempster1977}). Este método fue acoplado con éxito al filtro de Kalman tradicional para estimar $\v Q$ y $\v R$ en \cite{Shumway1982} y con posteridad al filtro de Kalman por ensambles combinado con un suavizador de Kalman por ensambles (ver por ejemplo \cite{Dreano2017}). Un buen compendio de todas estas técnicas se puede encontrar en \cite{Tandeo2020}.

Dentro de toda la variedad de métodos para la estimación de errores observacionales y de modelo distinguimos los métodos \textit{offline} de los \textit{online}. Los primeros toman una ventana de observaciones $\v y_{1:T}$ y dan en base a estas una única estimación para $\v Q$ y $\v R$ para todos los tiempos $t = 1, ..., T$. El algoritmo EM es usualmente implementado de esta manera, utilizando un lote (\textit{batch}) de observaciones (tal es el caso en \cite{Dreano2017, Tandeo2015, Pulido2018}) y aplican el EnKF en combinación con el EnKS. Este procedimiento se adaptó para filtros de partículas en \cite{Lucini2021} sorteando la necesidad de utilizar un suavizador de partículas. En muchas aplicaciones no se utilizan suavizadores porque sólo hay interés en las distribuciones filtrantes y pronósticos y se implementan alternando predicción con análisis. Esto ahorra el costo computacional del suavizado y el almacentamiento de todas las estimaciones anteriores necesarias para el suavizador. En estos escenarios es impráctica o inviable la aplicación de métodos de estimación \textit{offline} y se hace necesario utilizar técnicas \textit{online} (también llamadas secuenciales o adaptativas). Estas producen estimaciones de $\v Q$ y $\v R$ de manera secuencial, es decir en cada ciclo de asimilación y utilizando la información de la observación que está siendo procesada (y no de todo el lote de observaciones de manera simultánea). En el trabajo de \cite{Neal1998} se propone una adaptación \textit{online} para el algoritmo EM y, en el contexto de modelos de Markov escondidos, podemos mencionar el algoritmo propuesto en \cite{Cappe2009} que implementa ideas de EM secuencial acoplados a filtros de partículas y las implementaciones de \cite{Andrieu2003} que utilizan pseudo-verosimilitudes basadas en mini-lotes de datos. También es necesario mencionar que existen implementaciones \textit{online} para estimación de errores que no están basadas en EM como por ejemplo la que se puede encontrar en \cite{Berry2013}.

Para esta tesis, desarrollamos un nuevo método \textit{online} de estimación de error de modelo y observacional basado en EM compatible con filtros de partículas y con EnKFs. La técnica combina las ideas del \textit{batch} EM en la versón de \cite{Dreano2017} con las ideas expuestas por \cite{Cappe2009} y \cite{Andrieu2003} y el resultado está publicado en \cite{Cocucci2021}. Para dar una derivación del método desarrollaremos el algoritmo EM tradicional por lotes en \ref{sec:batchEM} y luego haremos la deducción teórica para adaptar al algoritmo EM a un esquema secuencial en \ref{sec:onlineEM}. Sin embargo, antes de introducir estos métodos haremos la relevante mención de la técnica de estado aumentado. Esta es una metodología muy sencilla de aplicar y que se suele utilizar para la estimación de parámetros ``físicos'' del modelo $\mathcal{M}_t$ y que sin embargo falla para la estimación de errores exponiendo la necesidad de tratar con métodos más involucrados.

\section{Estado aumentado} \label{sec:augmented_state}

En la sección anterior se dicutió la relevancia de utilizar estimaciones apropiadas de los errores involucrados. Los parámetros que codifican a estas incertezas suelen ser llamados parámetros ``estocásticos''. Por otro lado, distinguimos a los parámetros específicos al modelo transicional $\mathcal{M}_t$ los cuales suelen ser llamados parámetros ``determinísticos'' o ``físicos'' ya que usualmente son cantidades interpretables como parte de la dinámica subyacente de las variables de estado $\v x_t$. Es normal que no se cuente con un parametrización precisa del modelo de transición y por lo tanto se requiera de técnicas que permitan estimarlo a partir de mediciones del sistema. En parte, y como fue mencionado en la sección anterior, se puede dar cuenta de la imperfección en la parametrización de $\mathcal{M}_t$ a través del error de modelo y delegar a la estimación de este las incertezas de los parámetros determinísticos. Sin embargo, con la técnica conocida como ``estado aumentado'', es posible estimarlos individualmente y de esta manera calibrar el modelo. Esta consiste en incorporar los parámetros a las variables de estado e interpretarlas como cantidades no observadas del sistema. Si llamamos $\gv\theta_t$ a los parámetros que queremos estimar, construimos entonces el estado aumentado $\tilde{\v x}_t = (\v x_t, \gv \theta_t)$ (notemos la subindexación $t$ que incluímos porque este método admite que los parámetros varíen en el tiempo). Para poder implementar esta idea es necesario extender $\v H_t$ para que interprete a los parámetros como variables no observadas y a $\mathcal{M}_t$ para que actúe sobre estos.

Las técnicas de asimilación de datos pueden inferir sobre variables no observadas ya que la asimilación captura las correlaciones entre estas y las observaciones. En el caso de que esta correlación sea muy débil, el análisis será conservador respecto a la variable no observada que permanecerá cerca del pronóstico. Por lo tanto, este comportamiento se replica para los parámetros en estado aumentado y, en el caso que las correlaciones mencionadas sean los suficientemente fuertes, se podrán obtener estimaciones para los parámetros. Además, como estas estimaciones son secuenciales y siguen la lógica ``pronóstico-análisis'' como el resto de las variables de estado, es posible estimar parámetros con variación temporal dando lugar a un sistema que se auto-calibra \citep{Ruiz2013a}. Sin embargo, hay que mencionar que, como los parámetros son utilizados en el modelo para el paso de tiempo subsiguiente, si los cambios en el parámetro son muy bruscos el sistema tardará en capturarlos, de manera que la adaptividad del método está sujeta a que las variaciones temporales de los parámetros sean lo suficientemente lentas como para que el sistema pueda asimilarlas. 

Para la extensión de $\mathcal{M}_t$ sobre los parámetros es común considerar que actúa como la identidad sobre los parámetros considerando sobre estos una hipótesis de persistencia. Esto significa que si $\gv \theta \in \gv\Theta$ entonces $\mathcal{M}_t |_{\gv\Theta} (\gv \theta) = \gv \theta$. Sin embargo, esto puede causar que las estimaciones se limiten a los valores del prior por lo que es habitual incorporar una caminata aleatoria Gaussiana $\mathcal{M}_t |_{\gv\Theta} (\gv \theta) = \gv \theta + \gv\epsilon_t$ con $\gv\epsilon_t \sim \mathcal{N}(\v 0, \gv\Sigma_{\gv\epsilon})$. Esto contribuye a que el pronóstico de los parámetros consiga una mejor exploración del espacio paramétrico. El valor de $\gv\Sigma_{\gv\epsilon}$ cuantifica la magnitud de los pasos de la caminata aleatoria y se constituye como un hiperparámetro que se puede calibrar para mejorar la performance del sistema de asimilación. El método de estado aumentado también permite modelar una dinámica más compleja para la evolución de los parámetros si esto fuera necesario.

En la figura \ref{fig:augmented_state_example} podemos ver un experimento usando el EnKF en el modelo Lorenz-63 utilizando estado aumentado para estimar $\rho$. Consideramos que el valor verdadero de este parámetro varía en el tiempo de acuerdo a una función sinusoidal. El sistema es capaz de capturar estos cambios y las estimaciones sincronizan con el valor real del parámetro luego de unas pocas iteraciones. La varianza inicial del ensamble se eligió relativamente grande para una mejor exploración del espacio paramétrico.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{augmented_state_example.eps}
    \caption{Estimación del parámetro $\rho$ del modelo Lorenz-63 mediante estado aumentado utilizando el EnKF}
    \label{fig:augmented_state_example}
\end{figure}

La técnica de estado aumentado suele ser adecuada para muchos parámetros determinísticos. Sin embargo, no da buenos resultados para la estimación de parámetros estocásticos debido a la falta de correlación entre estos y la información observacional. En \cite{Delsole2010} se puede encontrar una definición algo más precisa de parámetros determinísticos y estocásticos así como una justificación más completa de por qué aumentar el estado con parámetros estocásticos no puede dar buenas estimaciones.

\ma{Quizas se pueda agregar como ejemplo la estimacion del sigma en una caminata aleatoria? Una referencia interesante es: https://doi.org/10.1175/MWR-D-14-00176.1}

\section{Algoritmo EM}

El algoritmo EM se utiliza para obtener estimadores de máxima verosimilitud en sistemas parcialmente observados. Es en realidad una metodología general y no una solución \textit{off-the-shelf}. Su aplicación más conocida es en el contexto de aprendizaje no supervisado para hacer \textit{clustering} modelando el problema con una mezcla de Gaussianas \citep{Bishop2006} pero tiene una gran diversidad de utilidades. Comenzaremos dando su forma general, luego su aplicación en lotes para estimación de matrices de covarianzas en \textit{state space models} con error aditivo Gaussiano y finalmente su adaptación \textit{online}.

El algoritmo EM se aplica en el contexto de un modelo probabilístico en el que contamos con una variable observada $\v y$, variables no observadas $\v x$ y parámetros $\gv\theta$ el cual describe a la probilidad conjunta $p(\v x,  \v y; \gv\theta)$. El objetivo es utilizar datos $\v y$ para estimar el parámetro $\gv\theta$ mediante la maximización de la verosimilitud $p(\v y; \gv\theta)$ o equivalentemente, de su logaritmo. Si dotamos a las variables no observadas de una distribución \textit{a priori} $q(\v x)$ arbitraria podemos obtener la expresión:

\begin{align}
    \log p(\v y; \gv\theta) &=  \log \int p(\v x, \v y; \gv\theta) d\v x \\
    &=  \underbrace{\int q(\v x) \log \frac{q(\v x)}{p(\v x | \v y; \gv\theta)} d\v x}_{KL(\int q(\v x) \rVert p(\v x | \v y; \gv\theta))} + \underbrace{\int q(\v x) \log \frac{p(\v x, \v y; \gv\theta)}{q(\v x)} d\v x}_{\mathcal{L}(q, \gv\theta)} \label{eq:elbo_KL}
\end{align}
\ma{por que se cambia de notacion y se usa mayusculas en lugar d eminusculas para las variables?}
donde $KL$ es la divergencia de Kullback-Leibler y $\mathcal{L}$ es llamada ELBO (\textit{evidence lower bound}). Es común interpretar a $KL$ como una ``distancia'' entre probabilidades y de hecho, cumple que $KL(q \rVert p) \geq 0$ y se anula sí y sólo si $p = q$ en casi todo punto \footnote{Sin embargo notar que la $KL$ no es simetrica por lo que no es un distancia propiamente dicha.}. Al ser $KL$ mayor o igual a 0, esto significa que $\log p(\v y; \gv\theta) \geq \mathcal{L}(q, \gv\theta)$, es decir que la ELBO es una cota inferior de la log-verosimilitud.  

El algoritmo EM provee estimaciones $\gv\theta_0, \gv\theta_1, ...$ tales que $\log p(\v y; \gv\theta_{t+1}) \geq \log p(\v y; \gv\theta_t)$ que convergen a un máximo local de la verosimilitud \citep{Wu1983}. Como dado un $q$ fijo, la $\mathcal{L}(q,\gv\theta)$ es una cota inferior de $\log p(\v y; \gv\theta)$ para todo $\gv\theta$, entonces la idea es maximizar $\mathcal{L}(q,\gv\theta)$ primero respecto a $q$ y luego respecto a $\gv\theta$. Supongamos que ya contamos con la estimación de la $t$-ésima iteración, $\gv\theta_t$. Si queremos obtener $q = \argmax\limits_{q}\mathcal{L}(q,\gv\theta_t)$, notemos que la igualdad \ref{eq:elbo_KL} se satisface para todo $q$ por lo que debemos elegir el valor que anule a la divergencia de Kullback-Leibler, es decir $q = p(\v x | \v y; \gv\theta_t)$. Luego, dejamos fijo $q$ y elegimos $\theta_{t+1} = \argmax\limits_{\gv\theta} \mathcal{L}(q,\gv\theta)$. De esta manera obtendremos que 
\begin{align*}
    \log p(\v y; \gv\theta_t) &= \mathcal{L}(p(\v x | \v y; \gv\theta_t), \gv\theta_t) + \overbrace{KL(p(\v x | \v y; \gv\theta_t) \rVert p(\v x | \v y; \gv\theta_t))}^{0} \\
    &= \mathcal{L}(p(\v x | \v y; \gv\theta_t), \gv\theta_t) \\
    &\leq \mathcal{L}(p(\v x | \v y; \gv\theta_t), \gv\theta_{t+1}) \\
    % &\leq \mathcal{L}(p(\v x | \v y; \gv\theta_t), \gv\theta_{t+1}) + \overbrace{KL(p(\v x | \v y; \gv\theta_t) \rVert p(\v x | \v y; \gv\theta_{t+1}))}^{\geq 0} \\
    &\leq \log p(\v y; \gv\theta_{t+1})
\end{align*}
y por lo tanto que las estimaciones producidas incrementan la verosimilitud.

Notemos además que una vez elegido $q$ tal que anule a la divergencia de Kullback-Liebler en la iteración $t$ obtenemos que:
\begin{align*}
    \mathcal{L}(p(\v x | \v y; \gv\theta_t), \gv\theta) &= \int p(\v x | \v y; \gv\theta_t) \log \frac{p(\v x, \v y; \gv\theta)}{p(\v x | \v y; \gv\theta_t)} d\v x \\
    &= \int p(\v x | \v y; \gv\theta_t) \log p(\v x, \v y; \gv\theta) d\v x - \int p(\v x | \v y; \gv\theta_t) \log p(\v x | \v y; \gv\theta_t) d\v x \\
    &\propto_{\theta} \int p(\v x | \v y; \gv\theta_t) \log p(\v x, \v y; \gv\theta) d\v x \\
    &\dot{=} E_{\gv\theta_t}[\log p(\v x, \v y; \gv\theta)| \v y]
\end{align*}
es decir que la ELBO se puede expresar como una esperanza condicional una vez que elegimos $q$ que maximiza a $\mathcal{L}$. Debido a esto, la maximización sobre $q$ recibe el nombre de \textit{E-step}. Por otra parte el \textit{M-step} corresponde a la maximización sobre $\gv\theta$. El procedimiento admite entonces la caracterización que presentada en el Algoritmo \ref{algo:general_EM} en el que suponemos que se realizan una cantidad prefijada $N_{it}$ de iteraciones, aunque también es posible usar otros criterios de finalización.

\begin{algorithm}[H]\label{algo:general_EM}
    Elegir valor inicial $\gv\theta_0$: \\
    \For{$t=0, 1, ..., N_{it} $}{
        \textit{E-step}: \\
            \hspace{2em}Computar $\mathcal{Q}(\gv\theta, \gv\theta_t) = E_{\gv\theta_t}[\log p(\v x, \v y; \gv\theta)| \v y]$ \\
        
        \textit{M-step}: \\
            $\hspace{2em}\gv\theta_{t+1} = \argmax\limits_{\gv \theta} \mathcal{Q}(\gv\theta, \gv\theta_t)$
    }
\caption{EM general}
\end{algorithm}

La metodología que presentamos tiene la conveniencia de incrementar (o mantener) la verosimilitud en cada paso, sin embargo no garantiza que el máximo encontrado sea un máximo global de la verosimilitud. Cuando la probabilidad conjunta de las variables observadas y no observadas pertenece a la familia exponencial, tenemos simplificaciones importantes en el cómputo y el máximo puede determinarse en forma analítica; esto no siempre es el caso y existen variantes del algoritmo EM que consideran hacer una maximización parcial el \textit{M-step} (EM generalizado). Otra generalización consiste en una optimización parcial en la elección de $q$ en el \textit{E-step} (EM incremental, \cite{Neal1998}) que se implementa mediante la incorporación secuencial de las observaciones. Este método ayuda a una convergencia más rápida del algoritmo, que de otro modo tiene una convergencia en muchos casos lenta. Además, es el punto de partida para las versiones \textit{online} del EM que veremos más adelate.

\paragraph{Ejemplo EM}

Para ilustrar algunas de las características del algoritmo EM consideraremos una varible unidimendional no observada $\v x \sim \mathcal{N}(\gv\theta_t, \sigma_x^2)$ y una observación que responde al modelo $\v y = (\v x + b)^2 + \gv \epsilon$ donde $\gv\epsilon \sim \mathcal{N}(\v 0, \sigma_y^2)$ y $b$ es un escalar. Es decir que tenemos una varible no observada que depende del parámetro verdadero $\gv\theta_t$ y una observación que corresponde a una función cuadrática de la realización de $\v x$ más ruido aditivo Gaussiano. Esto resulta en una log-verosimilitud bimodal como se representa en la figura \ref{fig:EM_example}. También se pueden ver las curvas de la ELBO para dos iteraciones del EM: éstas son cotas inferiores de la log-verosimilitud y en un punto ($\gv\theta = \gv\theta_i$) son iguales. La figura muestra que cada iteración necesariamente tendrá una verosimilitud mayor o igual a las anteriores. Por otro lado quedan en evidencia dos de las debilidades del método: por un lado la convergencia puede ser lenta  puesto que la maximización de la ELBO puede resultar en incrementos pequeños de la verosimilitud, y por otro lado, dependiendo de la estimación inicial $\gv\theta_0$, el algoritmo puede converger a un máximo local. En este ejemplo la convergencia es hacia el menor de los dos máximos, pero si la estimación inicial fuera menor al valor mínimo del valle entre estos el algoritmo convergería al estimador de máxima verosimilitud. Finalmente, notemos que la diferencia entre el máximo de la ELBO para la estimación $\gv\theta_i$ y el valor de la verosimilitud en ese punto es $KL(p(\v x | \v y; \gv\theta_{i-1}) \rVert p(\v x | \v y; \gv\theta_{i}))$ debido a la descomposición de la verosimilitud expresada en la ecuación \ref{eq:elbo_KL}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{EM_example.eps}
    \caption{Log-verosimilitud y ELBO para dos iteraciones del algoritmo EM}
    \label{fig:EM_example}
\end{figure}

\subsection{Batch EM} \label{sec:batchEM}

Los modelos de Markov escondidos son efectivamente sistemas parcialmente observados que en principio, admiten la aplicación del algoritmo EM. Pero además la estructura Markoviana de dependencia temporal de las variables no observadas junto a la independencia condicional de las observaciones puede ser utilizada para obtener una expresión más sencilla de la ELBO. Haremos ahora la suposición de que contamos con un modelo de Markov escondido en un intervalo de tiempos $t = 0, 1, ..., T$ para los cuales tenemos variables latentes $\v x_{0:T}$ y observaciones $\v y_{1:T}$. Las propiedades mencionadas sobre modelos de Markov escondidos nos permiten factorizar a la probabilidad conjunta (necesaria para computar la ELBO) como:
\begin{align}
    p(\v x_{0:T}, \v y_{1:T} ; \gv\theta) &= p(\v x_0 ; \gv\theta) \prod_{t=1}^T p(\v x_t | \v x_{t-1} ; \gv\theta) p(\v y_t | \v x_t ; \gv\theta) \\
    &= p(\v x_0 ; \gv\theta) \prod_{t=1}^T p(\v x_t, \v y_t | \v x_{t-1} ; \gv\theta) \label{eq:joint_factorization}
\end{align}

Para obtener la ELBO correspondiente a la $i$-ésima iteración del método, se elige a $q$ como la distribución de las variables latentes condicionadas a las observaciones y usando la expresión \ref{eq:joint_factorization} se tiene que:
\begin{align}
    \mathcal{L}(p(\v x_{0:T} | \v y_{1:T} ; \gv\theta_i), \gv\theta) &\propto_{\gv\theta} \sum_{t=1}^T \int p(\v x_{1:T} | \v y_{1:T} ; \gv\theta_i) \log p(\v x_t, \v y_t | \v x_{t-1} ; \gv\theta) d\v x_{1:T} \\
    &= \sum_{t=1}^T E_{\gv\theta_i} [\log p(\v x_t, \v y_t | \v x_{t-1} ; \gv\theta) | \v y_{1:T}]
\end{align}
En esta expresión hemos quitado el término correspondiente a $p(\v x_0 ; \gv\theta)$ bajo la suposición de que no hay parámetros desconocidos en la distribución inicial. Esta suposición no es necesaria y de hecho en \cite{Dreano2017} se opta por estimar su media y varianza como partes del vector de parámetros $\gv\theta$ considerados por el algoritmo EM. Ahora haremos una suposición extra que nos permitirá obtener una forma analítica del gradiente de la ELBO: supondremos que $p(\v x_t, \v y_t | \v x_{t-1} ; \gv\theta)$ pertenece a la familia exponencial. Este supuesto no es extremadamente restrictivo puesto que muchas distribuciones relevantes son de la familia exponencial incluyendo, importantemente, a la Gaussiana. En ese caso tendremos entonces que:
\begin{align*}
    p(\v x_t, \v y_t | \v x_{t-1} ; \gv\theta) = h(\v x_t, \v y_t) \exp(\psi(\gv\theta)\cdot s(\v x_{t-1}, \v x_t, \v y_t) - A(\gv\theta))
\end{align*}
donde $s(\v x_{t-1}, \v x_t, \v y_t)$ es llamado el estadístico suficiente, $\psi(\gv\theta)$ la parametrización natural y $h$ y $A$ son funciones \citep{Wasserman2004}. El gradiente de la ELBO respecto al parámetro se puede computar como:
\begin{align}
    \nabla_{\gv\theta} \mathcal{L}(p(\v x_{0:T} | \v y_{1:T} ; \gv\theta_i), \gv\theta) = \nabla_{\gv\theta} \psi(\gv\theta) \cdot \sum_{t=1}^T E_{\gv\theta_i} [s(\v x_{t-1}, \v x_t, \v y_t) | \v y_{1:T}] - T\nabla_{\gv\theta}A(\gv\theta)
\end{align}
con lo cual anulando el gradiente obtenemos la siguiente ecuación
\begin{align} \label{eq:null_elbo_grad}
    \nabla_{\gv\theta} \psi(\gv\theta) \cdot S_i - \nabla_{\gv\theta}A(\gv\theta) = 0
\end{align}
donde usamos la nomenclatura
\begin{align} \label{eq:S_def}
    S_i = \frac{1}{T}\sum_{t=1}^T E_{\gv\theta_i} [s(\v x_{t-1}, \v x_t, \v y_t) | \v y_{1:T}]
\end{align}
El valor del parámetro que cumpla con \ref{eq:null_elbo_grad} será el que maximice la ELBO y por lo tanto el valor subsiguiente del EM, $\gv\theta_{i+1}$. Más precisamente, el valor que anula el gradiente es un punto crítico pero en este caso está garantizado que es un máximo debido a propiedades del Hessiano en familias exponenciales \citep{Wainwright2008}. Notemos que la cantidad $S_i$ es un promedio sobre toda la ventana temporal $t=1, .., T$ de valores esperados de los estadísticos suficientes condicionados a \textit{todas} las observaciones y computado con la última estimación disponible del parámetro, $\gv\theta_i$. El condicionamiento sobre toda la ventana de observaciones implica que el valor esperado esta siendo computado utilizando las distribuciones suavizantes. El método EM que se obtiene para modelos de Markov escondidos bajo la hipótesis de familia exponencial consiste entonces en un \textit{E-step} en el que computamos $S_i$ (\ref{eq:S_def}) y un \textit{M-step} en el que resolvemos la ecuación que anula el gradiente de la ELBO (\ref{eq:null_elbo_grad}).

\subsubsection*{El caso Gaussiano}
Ahora trataremos el caso en el que el error observacional y de modelo sean aditivos y Gaussianos, es decir que tenemos:
\begin{align}
    p(\v x_t | \v x_{t-1}) &\sim \mathcal{N}(\mathcal{M}_t(\v x_{t-1}), \v Q) \\
    p(\v y_t | \v x_t) &\sim \mathcal{N}(\mathcal{H}_t(\v x_t), \v R)
\end{align}
y buscamos estimar $\gv\theta = (\v Q, \v R)$, las matrices de covarianzas del error de modelo y observacional respectivamente. Notemos que, no estamos considerando que estas matrices cambien en el tiempo, es decir que suponemos que son constantes en toda la ventana temporal. Además, debido a la independencia condicional de las observaciones de los modelos de Markov escondidos, tenemos que $p(\v x_t, \v y_t | \v x_{t-1}) = p(\v x_t | \v x_{t-1}) (\v y_t | \v x_t)$ y como supusimos que $p(\v x_t | \v x_{t-1})$ y $(\v y_t | \v x_t)$ son Gaussianas, esto implica que $p(\v x_t, \v y_t | \v x_{t-1})$ también lo es. Por lo tanto seguimos bajo la suposición de familia exponencial que enunciamos anteriormente. La cantidad $S_i$, en este caso puede ser pensada como una tupla $(S_i^{\v Q}, S_i^{\v R})$ y la podemos computar mediante las siguientes expresiones que corresponden al \textit{E-step}:
\begin{align}
    S_i^{\v Q} &= \frac{1}{T}\sum_{t=1}^T E_{\gv\theta_i}[(\v x_t - \mathcal{M}_t(\v x_{t-1}))(\v x_t - \mathcal{M}_t(\v x_{t-1}))^T | \v y_{1:T}] \label{eq:batchEM_SQ} \\
    S_i^{\v R} &= \frac{1}{T}\sum_{t=1}^T E_{\gv\theta_i}[(\v y_t - \mathcal{H}_t(\v x_t))(\v y_t - \mathcal{H}_t(\v x_t))^T | \v y_{1:T}] \label{eq:batchEM_SR}
\end{align}
Por otro lado, la ecuación \ref{eq:null_elbo_grad}, para el caso Gaussiano tiene como solución exactamente a la cantidad $S_i$, con lo cual el \textit{M-step} no requiere ningún cómputo adicional. La verificación de que $\gv\theta = S_i$ anula al gradiente de la ELBO se puede encontar en el apéndice (\ref{appendix:null_grad_elbo}) junto con la representación de una densidad Gaussiana multivariada como miembro de la familia exponencial (\ref{appendix:exp_family}).

Las ecuaciones \ref{eq:batchEM_SQ} y \ref{eq:batchEM_SR}, nos dan fórmulas para computar sucesivas estimaciones de $\v Q$ y $\v R$ y constituyen las fórmulas principales utilizadas en \cite{Tandeo2015, Dreano2017, Pulido2018}. Sin embargo, requieren el cómputo de valores esperados condicionados a la totalidad de la ventana de observaciones, $\v y_{1:T}$. Si se cuenta con una representación de partículas de las distribuciones suavizantes $p(\v x_t | \v x_{1:T})$ para todo $t$, entonces los valores esperados se pueden aproximar con estimadores de Monte Carlo. Notablemente, el EnKS es una técnica que provee estas distribuciones y que también es apropiada para sistemas con errores Gaussianos aditivos; por lo tanto es compatible con esta aplicación del EM. En el algoritmo \ref{algo:em_enks} podemos encontrar la implementación de este método.

\begin{algorithm}[H]\label{algo:em_enks}
    Muestrear ensamble inicial: $\{\v x_0^{a, (i)} \}_{i=1}^{N_p} \sim p(\v x_0)$ \\
    Elegir valor inicial $\gv\theta_0 = (\v Q_0, \v R_0)$:\\
    \For{$i=1, ..., N_{it}$}{
        \textit{E-step}:
        Computar los ensambles de pronóstico, filtrantes usando EnKF con la parametrización $\gv\theta_{i-1}$
            \begin{flalign*}
                \hspace{2em} \{ \v x_t^{f, (j)} \}_{j=1}^{N_p} &\sim p(\v x_t | \v y_{1:t-1}) \hspace{2em} \forall t=1, ..., T && \\
                \hspace{2em} \{ \v x_t^{a, (j)} \}_{j=1}^{N_p} &\sim p(\v x_t | \v y_{1:t}) \hspace{2em} \forall t=1, ..., T &&
            \end{flalign*}
        Utilizar los ensambles de pronóstico y filtrantes para computar los suavizantes mediante EnKS:
            \begin{flalign*}
                \hspace{2em}\{\v x_t^{s, (j)} \}_{j=1}^{N_p} \sim p(\v x_t | \v y_{1:T}) \hspace{2em} \forall t=1, ..., T &&
            \end{flalign*}
            \begin{flalign*}
                \hspace{2em} S_i^{\v Q} &= \frac{1}{T} \sum_{t=1}^{T} \frac{1}{N_p} \sum_{j=1}^{N_p} (\v x_t^{s, (j)} - \mathcal{M}_t(\v x_{t-1}^{s, (j)}))(\v x_t^{s, (j)} - \mathcal{M}_t(\v x_{t-1}^{s, (j)}))^T && \\
                \hspace{2em} S_i^{\v R} &= \frac{1}{T} \sum_{t=1}^{T} \frac{1}{N_p} \sum_{j=1}^{N_p} (\v y_t - \mathcal{H}_t(\v x_t^{s, (j)}))(\v y_t - \mathcal{H}_t(\v x_t^{s, (j)}))^T &&
            \end{flalign*}
        \textit{M-step}: \\
            Asignar nuevos parámetros $\gv\theta_i = (\v Q_i, \v R_i)$
            \begin{flalign*}
                \hspace{2em} \v Q_i &= S_i^{\v Q} && \\
                \hspace{2em} \v R_i &= S_i^{\v R} &&
            \end{flalign*}
    }
\caption{EM-EnKS}
\end{algorithm}

Podemos ver que el algoritmo involucra, para cada iteración, procesar las iteraciones hacia adelante mediante predicción y filtrado con el EnKF, reprocesarlas hacia atrás con el EnKS y luego computar con Monte Carlo las actualizaciones de los parámetros. Las pasadas hacia adelante y hacia atrás provienen de que el EnKF y EnKS son implementaciones del algoritmo \textit{forward-backward}. Esto significa que para utilizar este algoritmo debemos procesar todas las observaciones reiteradas veces. Además del costo computacional, esto implica que las observaciones tienen que ser almacenadas y no se contempla una posible incorporación de nuevas observaciones, situación que sería esperable en un sistema en tiempo real. Aunque el \textit{batch EM} combinado con EnKS es un método robusto para estimar la estrctura general de $\v Q$ y $\v R$ su naturaleza \textit{offline} lo puede hacer impráctico en algunas situaciones y demasiado costoso computacionalmente. Además, no siempre es posible o factible obtener valores esperados respecto a distribuciones suavizantes. Por estos motivos se han desarrollado técnicas \textit{online} o secuenciales de estimación de parámetros estocásticos. 

\paragraph{Ejemplo EM-EnKS} \

Hacemos aquí una aplicación de el EM-EnKS sobre el modelo del oscilador armónico para la estimación conjunta de $\v Q$ y $\v R$. En la figura \ref{fig:em_enks_params} podemos ver el error cuadrático medio entre las estimaciones y el valor real de los parámetros utilizados para generar las observaciones. Además mostramos la media de la diagonal de las matrices estimadas en cada iteración. En realidad cada entrada de las matrices está siendo estimada individualmente (salvo por los elementos simétricos respecto a la diagonal). Notamos que la convergencia es rápida en las primeras iteraciones y luego se desacelera. En la figura \ref{fig:em_enks_rmse_llik} se muestra el error cuadrático medio de las variables de estado suavizadas respecto a los respectivos valores reales y la log-verosimilitud de las observaciones computada mediante la siguiente aproximación dessarrollada en mayor detalle en \ref{appendix:likelihood_montecarlo}:
\begin{align}
    \log p(\v y_{1:T}) \approx \sum_{t=1}^{T} \log \frac{1}{N_p} \sum_{j=1}^{N_p} p(\v y_t | \v x_t^{f, (j)}) \label{eq:likelihood_montecarlo}
\end{align}
Se puede ver que mientras el RMSE disminuye, la verosimilitud aumenta. Notamos también que ambas métricas, son ruidosas debido a que la técnica de asimilación sólo aproxima mediante muestras a las distribuciones.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{em_enks_params.eps}
    \caption{Panel superior: estimaciones de las medias de las diagonales de $\v Q$ y $\v R$. Las líneas intermitentes indican los valores reales. Panel inferior: errores cuadráticos medios de las estimaciones respecto a sus valores reales.}
    \label{fig:em_enks_params}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{em_enks_rmse_llik.eps}
    \caption{Log-verosimilitud y RMSE de las variables de estado suavizadas en cada iteración.}
    \label{fig:em_enks_rmse_llik}
\end{figure}

\subsection{EM \textit{online}} \label{sec:onlineEM}

Aquí expondremos el algoritmo \textit{online} basado en EM cuyo desarrollo fue publicado en \cite{Cocucci2021}. El objetivo es obtener una técnica que actualice la estimación del parámetro con cada nueva observación de manera que se puedan descartar las observaciones anteriores que ya han sido procesadas. Si tomamos como punto de partida las ecuaciones \ref{eq:batchEM_SQ} y \ref{eq:batchEM_SR} podemos ver que, cada sumando corresponde a una observación pero que si quisiéramos agregar una observación nueva (correspondiente al tiempo $T+1$) todos estos sumandos deberían ser recomputados. Esto es debido a que los valores esperados están condicionados a toda la ventana observacional anterior, $\v y_{1:T}$. Las nuevas distribuciones predictivas y filtrantes, $p(\v x_{T+1} | \v y_{1:T})$ y $p(\v x_{T+1} | \v y_{1:T+1})$ pueden ser obtenidas o aproximadas utilizando las anteriores distribuciones predictivas y filtrantes que no necesitan ser cambiadas por la incorporación de la nueva observación. Sin embargo, las distribuciones suavizantes $p(\v x_t | \v y_{1:T})$ deben ser cambiadas en cada $t$ por las que tienen en cuenta a la nueva observación, $p(\v x_t | \v x_{1:T+1})$.

En este punto, dado que buscamos procesar observaciones que se hacen disponibles una por una, cambiaremos la notación de las iteraciones del EM y la haremos coincidir con la de las observaciones, puesto que queremos obtener una actualización de los parámetros por cada observación. Entonces consideramos que tenemos observaciones $\v y_{1:T+1}$ y estimaciones de los parámetros $\gv\theta_0, ..., \gv\theta_T$, y buscaremos, a partir de esto, obtener la estimación $\gv\theta_{T+1}$. Más precisamente, buscaremos actualizaciones de la ELBO, es decir que dada una secuencia $S_1, ..., S_T$ buscaremos actualizar $S_T$ para que incorpore la obeservación $\v y_{T+1}$ de manera de obtener $S_{T+1}$. Esto es porque al hacer una extensión \textit{online} de el \textit{E-step} dotamos de esta propiedad a todo el algoritmo, pues el \textit{M-step} seguirá consistiendo en solucionar \ref{eq:null_elbo_grad} para $\gv\theta$ una vez computado $S_{T+1}$. Comenzamos entonces escribiendo la definición de $S_{T+1}$ como en \ref{eq:S_def} con la nueva notación y desglosando la suma de la siguiente manera:
\begin{align}
    S_{T+1} &= \frac{1}{T+1}\sum_{t=1}^{T+1} E_{\gv\theta_T} [s(\v x_{t-1}, \v x_t, \v y_t) | \v y_{1:T+1}] \\
    &= \frac{1}{T+1}\sum_{t=1}^{T+1} \int p(\v x_{t-1}, \v x_t | \v y_{1:T+1}; \gv\theta_T) s(\v x_{t-1}, \v x_t, \v y_t) d\v x_{t-1:t}\\
    &= \frac{1}{T+1} \left( \sum_{t=1}^{T} \int p(\v x_{t-1}, \v x_t | \v y_{1:T+1}; \gv\theta_T) s(\v x_{t-1}, \v x_t, \v y_t)  d\v x_{t-1:t} \right.\\ 
    &\left. + \int p(\v x_{T}, \v x_{T+1} | \v y_{1:T+1}; \gv\theta_T) s(\v x_{T}, \v x_{T+1}, \v y_{T+1}) d\v x_{T:T+1} \right)
\end{align}
Podemos identificar entonces que los primeros $T$ términos de la suma son similares a la cantidad $S_T$ con la salvedad de que en el condicionamiento del valor esperado se incluye la información de la última observación. Haciendo entonces la suposición de que esta última observación no afecta significativiamente a los estados anteriores y sólo influye en el último término se motiva la siguiente aproximación:
\begin{align}
    \widehat{S_{T+1}} &= \left(1 - \frac{1}{T+1}\right) \widehat{S_T} + \frac{1}{T+1} \int p(\v x_{T}, \v x_{T+1} | \v y_{1:T+1}; \gv\theta_T) s(\v x_{T}, \v x_{T+1}, \v y_{T+1}) d\v x_{T:T+1} \\
    &= (1 - \gamma_{T+1}) \widehat{S_T} + \gamma_{T+1} E_{\gv\theta_T} [s(\v x_T, \v x_{T+1}, \v y_{T+1}) | \v y_{1:T+1}] \label{eq:onlineEM_S_rescursion}
\end{align}

Tenemos entonces una fórmula que nos permite computar las aproximaciones $\widehat{S_t}$ para todo $t$ de manera recursiva en base a $S_{t-1}$. Para iniciar la recursión es necesario que contemos con una aproximación inicial $S_0$. Además introducimos $\gamma_t$ que, si bien debe valer $1/t$ para satisfacer \ref{eq:onlineEM_S_rescursion}, puede ser interpretada como una tasa de aprendizaje $\gamma_t \in (0, 1)$, tomando como inspiración técnicas de aproximación estocástica \cite{Legland1997}. Este parámetro va a controlar la ``memoria'' de los estimadores, es decir, pondera la importancia de las estimaciones anteriores respecto al nuevo término que incluye a la última observación. Como veremos luego este parámetro se puede calibrar para obtener comportamientos distintos del método en cuanto a convergencia. Notemos que con este esquema se puede flexibilizar la hipótesis del EM batch de que los parámetros no varían y podemos considerar casos en que los parámetros varíen lentamente en el tiempo. El método resultante tiene algunas similitudes con el propuesto en \cite{Cappe2009} en el que se utiliza una función auxiliar, relacionada a una forma recusiva de suavizado, que permite mantener actualizaciones de $S_t$. Podemos ver que, a pesar de evitar un suavizado hacia atrás hasta la primera observación, el cómputo del valor esperado en \ref{eq:onlineEM_S_rescursion} implica un suavizado de un paso hacia atrás porque el estadístico $s$ depende de $\v x_T$ y el condicionamiento incluye a $\v y_{T+1}$. 

En el algoritmo \ref{algo:onlineEM} se esquematiza el procedimiento de manera general. Notemos que no consideramos una ventana finita de observaciones porque potencialmente se puede seguir iterando a medida que nuevos datos se hacen disponibles. Por otro lado, no hacemos suposiciones sobre los valores iniciales pero sería natural tomar $S_0$ y $\gv\theta_0$ tales que satisfagan \ref{eq:null_elbo_grad}.

\begin{algorithm}[H]\label{algo:onlineEM}
    Elegir valor inicial para el parámetro, $\gv\theta_0$ y el estadístico, $\widehat{S_0}$: \\
    \For{$t = 1, 2, ...$}{
        \textit{E-step}: \\
        $\hspace{2em}\widehat{S_{t}} = (1 - \gamma_{t}) \widehat{S_{t-1}} + \gamma_{t} E_{\gv\theta_{t-1}} [s(\v x_{t-1}, \v x_t, \v y_t) | \v y_{1:t}] $ \\
        \textit{M-step}: \\
        Definir $\gv\theta_t$ como el valor de $\gv\theta$ que solucione: \\
        $\hspace{2em}\nabla_{\gv\theta} \psi(\gv\theta) \cdot \widehat{S_t} - \nabla_{\gv\theta}A(\gv\theta) = 0$ 
        }
        \caption{EM \textit{online}}
\end{algorithm}

De acuerdo a como se compute o aproxime el valor esperado
\begin{align}
    E_{\gv\theta_{t-1}} [s(\v x_{t-1}, \v x_t, \v y_t) | \v y_{1:t}] = \int p(\v x_{t-1}, \v x_t| \v y_{1:t} ; \gv\theta_{t-1}) s(\v x_{t-1}, \v x_t, \v y_t) d\v x_{t-1:t} \label{eq:onlineEM_expected}
\end{align}
tendremos distintas implementaciones del método. En particular daremos dos posibles formas de aproximar esta integral con Monte Carlo. El primero de los métodos está basado en muestreo de importancia y está pensado para ser acoplado a filtros de partículas. La elección de la distribución de importancia evita hacer un paso de suavizado explícito. El segundo se basa en EnKF y agrega un paso hacia atrás de suavizado de manera explícita usando EnKS. 

\subsubsection*{EM \textit{online} con muestreo de importancia} \label{sec:onlineEM_IS}

Para elegir una distribución de importancia conveniente para aproximar \ref{eq:onlineEM_expected} primero desarrollaremos $p(\v x_{t-1}, \v x_t| \v y_{1:t}; \gv\theta_{t-1})$ de la siguiente manera, quitando la dependencia de $\gv\theta_{t-1}$ para mayor claridad:
\begin{align}
    p(\v x_{t-1}, \v x_t| \v y_{1:t}) &= p(\v x_t | \v x_{t-1}) p(\v x_{t-1} | \v y_{1:t-1}) \frac{p(\v y_t | \v x_t)}{p(\v y_t | \v y_{1:t-1})} \label{eq:IS_factorization}
\end{align}
En la factorización (desarrollada con mayor detalle en el apéndice \ref{appendix:IS_factorization}) podemos reconocer al modelo de transición y observacional, a la probabilidad filtrante a tiempo $t-1$ y a la cantidad $p(\v y_t | \v y_{1:t-1})$ que suele ser llamada verosimilitud marginalizada y que no depende de las variables de integración $\v x_{t-1}$ y $\v x_t$. Para aproximar entonces \ref{eq:onlineEM_expected} con muestreo de importancia debemos tener muestras de ambas variables de integración. En lugar de muestrear directamente de $p(\v x_{t-1}, \v x_t| \v y_{1:t})$ \ref{eq:IS_factorization} sugiere que podemos muestrear de $p(\v x_t | \v x_{t-1}) p(\v x_{t-1} | \v y_{1:t-1})$ y obtener pesos proporcionales a $p(\v y_t | \v x_t)$ y, mientras que nos aseguremos de normalizar los pesos, no debemos preocuparnos por la verosimilitud marginal. Esto es conveniente porque disponemos del modelo observacional, $p(\v y_t | \v x_t)$ para evaluar los pesos. Además, como cualquier técnica de filtrado por ensambles produce muestras de la distribución filtrante ya disponemos de las partículas correspondientes a $\v x_{t-1}$ y para obtener las de $\v x_t$ podemos utilizar el modelo de transición.

Si estamos utilizando un método por ensambles de $N_p$ partículas, podemos utilizar nuestra muestra de la distribución filtrante,
\begin{align*}
    \{ \v x_{t-1}^{a, (j)}\}_{j=1}^{N_p} \sim p(\v x_{t-1} | \v y_{1:t-1} ; \gv\theta_{t-1})
\end{align*}
y en base a cada partícula de esta muestra obtener otra, cuyo tamaño denominamos $M_p$, correspondiente a $\v x_t$:
\begin{align*}
    \{ \v x_{t}^{f, (j,l)}\}_{l=1}^{M_p} \sim p(\v x_t | \v x_{t-1}^{a, (j)} ; \gv\theta_{t-1})
\end{align*}
Estas últimas $N_p M_p$ partículas llevan el superíndice $f$ pues se obtienen de la misma manera en que se obtendría un pronóstico (\textit{forecast}) pero haciendo la salvedad de que tenemos $M_p$ partículas por cada punto del tiempo anterior. Con estas muestras podemos ya calcular los pesos no normalizados,
\begin{align*}
    \overline{w_{j,l}} = p(\v y_t | \v x_t^{(j,l)})
\end{align*}
y una vez que obtenemos las versiones normalizadas, $w_{j,l}$ podemos hacer la aproximación de Monte Carlo de la integral:
\begin{align*}
    E_{\gv\theta_{t-1}} [s(\v x_{t-1}, \v x_t, \v y_t) | \v y_{1:t}] \approx \sum_{j=1}^{N_p} \sum_{l=1}^{M_p} w_{j, l} s(\v x_{t-1}^{a, (j)}, \v x_{t}^{f, (j,l)}, \v y_t)
\end{align*}

Este método puede ser implementado con cualquier técnica de asimilación de datos por ensambles ya que solo necesitamos: una representación de partículas filtrante, evaluar el modelo observacional ($p(\v y_t | \v x_t)$) y muestrear del modelo de transición ($p(\v x_t | \v x_{t-1})$), es decir evolucionar el modelo hacia adelante. Por lo tanto, la metodología es compatible con EnKF y filtros de partículas. Notemos también que  es posible tomar $M_p = 1$ pues esto es equivalente a muestrear $(\v x_{t-1}, \v x_t)$ de manera conjunta de la distribución $p(\v x_t | \v x_{t-1}) p(\v x_{t-1} | \v y_{1:t-1}) = p(\v x_t, \v x_{t-1} | \v y_{1:t-1})$. El algoritmo \ref{algo:onlineEM_IS} especifica el método.

\begin{algorithm}[H]\label{algo:onlineEM_IS}

    Muestrear partículas iniciales: $\{\v x_0^{(j)}\}_{j=1}^{N_p} \sim p(\v x_0)$ \\
    Elegir valor inicial para el parámetro, $\gv\theta_0$ y el estadístico, $\widehat{S_0}$: \\
    \For{$t = 1, 2, ...$}{
    Calcular pesos:\\
    \For{$j=1, ..., N_p$}{
        \For{$l=1, ..., M_p$}{
                $\v x_{t}^{f, (j,l)} \sim p(\v x_{t} | \v x_{t-1}^{a, (j)};\gv\theta_{t-1})$ \\
                $w_{j,l} \propto p(\v y_{t} | \v x_{t}^{f, (j,l)} ; \gv\theta_{t-1})$
        }
    }
    Muestrear partículas filtrantes:\\
    $\hspace{2em}\{\v x_{t}^{a, (j)}\}_{j=1}^{N_p}  \sim p(\v x_{t} | \v y_{1:t};\gv\theta_{t-1})$\\
    Computar $\widehat{S_t}$: \\
    $\hspace{2em}\widehat{S_{t}} = (1 - \gamma_{t}) \widehat{S_{t-1}} + \gamma_{t} \sum_{j=1}^{N_p} \sum_{l=1}^{M_p} w_{j, l} s(\v x_{t-1}^{a, (j)}, \v x_{t}^{f, (j,l)}, \v y_t) $ \\
    Definir $\gv\theta_t$ como el valor de $\gv\theta$ que solucione: \\
    $\hspace{2em}\nabla_{\gv\theta} \psi(\gv\theta) \cdot \widehat{S_t} - \nabla_{\gv\theta}A(\gv\theta) = 0$
    }
\caption{EM \textit{online} con muestreo de importancia}
\end{algorithm}

\subsubsection*{EM \textit{online} con un paso de suavizado} \label{sec:onlineEM_OSS}

Una segunda propuesta para obtener una aproximación de Monte Carlo de \ref{eq:onlineEM_expected} es muestrear directamente de $p(\v x_{t-1}, \v x_t| \v y_{1:t})$ para lo cual es necesario obtener la versión suavizada del estado a tiempo $t-1$. El EnKF puede proveernos las partículas correspondientes a $p(\v x_t | \v y_{t-1})$ mientras que podemos obtener una muestra de $p(\v x_{t-1} | \v y_{1:t})$ mediante el EnKS, presentado en el algoritmo \ref{algo:enks}. Notemos además que no es necesario iterar con el EnKS hasta la primera observación sino que basta con hacer un solo paso hacia atrás pues no estamos interesados en las partículas de tiempos anteriores a $t-1$. De esta manera, muestreamos:
\begin{align*}
    \{\v x_t^{a, (j)}\}_{j=1}^{N_p} &\sim p(\v x_t | \v x_{1:t}) \\
    \{\v x_t^{s, (j)}\}_{j=1}^{N_p} &\sim p(\v x_{t-1} | \v x_{1:t})
\end{align*}
donde las partículas suavizantes pueden ser obtenidas del ensamble de pronóstico y el filtrante utilizando las siguientes expresiones:
\begin{align*}
    \v K_{t-1}^s &= \v S_{t-1}^a ( {\v S_t^f}^T \v S_t^f )^{-1} {\v S_t^f}^T \\
    \v x_{t-1}^{j, (s)} &= \v x_{t-1}^{j, (s)} + \v K_{t-1}^s (\v x_t^{j, (s)} - \v x_t^{j, (f)})
\end{align*}
donde $\v S_t^f$ y $\v S_t^a$ son tal como se las especifica en la sección \ref{sec:enkf}. Notemos que, cuando $\v y_t$ es la última observación disponible, la distribución filtrante coincide con la suavizante a ese tiempo y por lo tanto $\v x_t^{s, (j)} = \v x_t^{a, (j)}$. La aproximación de Monte Carlo resulta entonces en:
\begin{align*}
    E_{\gv\theta_{t-1}} [s(\v x_{t-1}, \v x_t, \v y_t) | \v y_{1:t}] \approx \sum_{j=1}^{N_p} s(\v x_{t-1}^{s, (j)}, \v x_{t}^{a, (j)}, \v y_t)
\end{align*}
y la metodología puede ser entonces expresada en forma algorítmica como se expone en el Algoritmo \ref{algo:onlineEM_OSS}.

\begin{algorithm}[H]\label{algo:onlineEM_OSS}
    
    Muestrear partículas iniciales: $\{\v x_0^{(j)}\}_{j=1}^{N_p} \sim p(\v x_0)$ \\
    Elegir valor inicial para el parámetro, $\gv\theta_0$ y el estadístico, $\widehat{S_0}$: \\
    \For{$t = 1, 2, ...$}{
        Computar partículas filtrantes y suavizantes utilizando EnKF+EnKS:\\
    $\hspace{2em}\{\v x_t^{a, (j)}\}_{j=1}^{N_p} \sim p(\v x_t | \v y_{1:t};\gv\theta_{t-1})$ \\
    $\hspace{2em}\{\v x_{t-1}^{s, (j)}\}_{j=1}^{N_p} \sim p(\v x_{t-1} | \v y_{1:t};\gv\theta_{t-1})$ \\
    Computar $\widehat{S_t}$: \\
    $\hspace{2em}\widehat{S_{t}} = (1 - \gamma_{t}) \widehat{S_{t-1}} + \gamma_{t} \frac{1}{N_p}\sum_{j=1}^{N_p} s(\v x_{t-1}^{s, (j)}, \v x_{t}^{a, (j)}, \v y_t) $ \\
    Definir $\gv\theta_t$ como el valor de $\gv\theta$ que solucione: \\
    $\hspace{2em}\nabla_{\gv\theta} \psi(\gv\theta) \cdot \widehat{S_t} - \nabla_{\gv\theta}A(\gv\theta) = 0$
    }
    \caption{EM \textit{online} con suavizado de un paso}
\end{algorithm}
No especificamos que implementación de EnKF o EnKS utilizamos porque potencialmente podemos elegir la que resulte más conveniente. Al estar basado en el filtro de Kalman por ensambles, se tienen los requerimientos usuales para dicho método, es decir errores aditivos Gaussianos en el modelo de transición y observacional. Si consideramos que en el caso Gaussiano, el estadístico suficiente 
se puede expresar como $s(\v x_{t-1}, \v x_t, \v y_{1:t}) = (s^Q(\v x_{t-1}, \v x_t), s^R(\v y_t, \v x_t))$ donde
\begin{align*}
    s^Q(\v x_{t-1}, \v x_t) &= (\v x_t - \mathcal{M}_t(\v x_{t-1}))(\v x_t - \mathcal{M}_t(\v x_{t-1}))^T \\
    s^R(\v y_t, \v x_t) &= (\v y_t - \mathcal{Y}_t(\v x_t))(\v y_t - \mathcal{H}_t(\v x_t))^T
\end{align*}
podemos ver la similaridad entre este método y el EM-EnKS presentado en el algoritmo \ref{algo:em_enks}. Sin embargo, si aplicaramos  la versión \textit{online} a una ventana de tiempo $t = 1, ..., T$, podemos ver que este realiza aproximadamente la misma cantidad de operaciones en total que una única iteración de la versión \textit{offline}. De hecho, el EM \textit{online} requerirá $T$ pasos temporales de EnKF y $T$ pasos simples (de una sola observación) hacia atrás de EnKS: esto es equivalente al pase completo de EnKF+EnKS en la versión \textit{batch}. Por otro lado, la cantidad de evaluaciones de $s$ en el pase completo de la versión \textit{online} es $N_p T$, lo cual coincide con una única iteración del \textit{offline}. El costo computacional es entonces menor para la versión \textit{online} y de aplicación más directa a sistemas secuenciales.

En la implementación de muestreo de importancia, los ensambles representan muestras de las distribuciones. En esta versión basada en EnKF también pero con la importante salvedad de que las muestras están computadas bajo suposiciones de Gaussianidad. Esto significa que se considera que las distribuciones pueden ser representadas solamente con los dos primeros momentos mientras que los de orden superior son ignorados.

\subsection{EM \textit{online}: evaluación experimental}

Expondremos aquí una evaluación experimental del método en distintos escenarios de interés para aplicaciones en asimilación de datos. La configuración de los experimentos consiste en generar trayectorias reales de las variables de estado, mediante la llamada simulación real o natural, y de estas obtener observaciones sintéticas con parametrizaciones conocidas para $\v Q$ y $\v R$. Luego aplicaremos el EM \textit{online} para estimar las variables de estado e importantemente la parametrización original. Sólo utilizamos como fuente de informacion las observaciones sintéticas, es decir que el sistema desconoce las covarianzas y la simulación natural. Utilizaremos el Algoritmo \ref{algo:onlineEM_OSS} con el EnKF estocástico (Algoritmo \ref{algo:enkf_pert_obs}) y el paso de suavizado hacia atrás mediante el RTS-EnKS (Algoritmo \ref{algo:enks}) pero realizando un solo paso hacia atrás. Daremos a esta implementación el nombre OSS-EnKF (por \textit{one step smoother}). Por otro lado, para el Algoritmo \ref{algo:onlineEM_IS} utilizaremos dos implementaciones distintas, una con el EnKF estocástico la cual llamaremos IS-EnKF (por \textit{importance sampling}) y otra con el VMPF la cual denominaremos IS-VMPF. Para esta última implementación notamos que la estimación de la matriz de covarianzas del error de modelo $\v Q$ tiene una relevancia adicional pues utilizamos un kernel $K(\v x, \v x') = (\v x - \v x')^T \beta \v Q (\v x - \v x')$, por lo que el ancho de banda del kernel dependerá de las estimaciones de $\v Q$. Para todas las versiones del EM \textit{online} utilizaremos una tasa de aprendizaje $\gamma_t = t^{-\alpha}$ \citep{Legland1997} donde el valor por defecto es $\alpha = 0.6$ con la excepción de un experimento en el que evaluaremos la performance para distintos valores de $\alpha$. En base a los resultados de dicho experimento es que tomamos el valor por defecto $\alpha = 0.6$.

\subsubsection{Consistencia respecto a valores iniciales}
En este experimento utilizamos el modelo Lorenz-63 y estimamos $\v Q$ con las 3 implementaciones, considerando a $\v R$ conocido. Esto se repite para distintas semillas de los generadores aleatorios y distintos valores iniciales del parámetro. El objetivo es evaluar la consistencia de las estimaciones y la comparabilidad de los métodos. La matriz $\v Q$ utilizada en en la simulación natural es un múltiplo de la identidad. En la figura \ref{fig:lor63_seeds} se muestran las estimaciones de la media de la diagonal de $\v Q$, es decir la varianza media del error de modelo. Notemos que las trayectorias grises corresponden a repeticiones del experimento y no deben ser confundidas con miembros de ensamble, de hecho el método produce una única estimación por iteración. Sin embargo, las repeticiones nos dan una idea de la incerteza de las estimaciones la cual se estabiliza alrededor de los 500 ciclos. Los tres métodos estiman correctamente el valor real del parámetro aunque los basados en importance sampling muestran una ligera subestimación. La velocidad de convergencia y la variabilidad en las estimaciones es también similar en todos los métodos.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{lor63_seeds.eps}
    \caption{Estimaciones de la media de la diagonal de $\v Q$ con OSS-EnKF (panel superior), IS-EnKF (panel medio) y IS-VMPF (panel inferior).}
    \label{fig:lor63_seeds}
\end{figure}

\subsubsection{Efecto de la tasa de aprendizaje}
Para evaluar el efecto de la tasa de aprendizaje en las estimaciones realizamos un experimento similar al anterior: estimamos una matriz $\v Q$ diagonal considerando $\v R$ conocida en el modelo Lorenz-63. En cada simulación utilizamos el mismo set de observaciones sintéticas pero cambiamos el valor de $\alpha$ de la tasa de aprendizaje. En la figura \ref{fig:lor63_alphas} se muestran las estimaciones para la media de la diagonal de $\v Q$. Para valores mayores de $\alpha$ la convergencia es lenta e incluso puede no lograrse en 10000 ciclos de asimilación. Por otro lado, para valores más pequeños se obtiene una convergencia mucho más rápida. Las estimaciones que produce el método son una ponderación entre la estimación de la iteración anterior con el promedio de los estadísticos suficientes correspondientes a la observación que está siendo procesada. Cuando $\alpha$ es más cercano a 1 se da más peso a la estimación anterior y menos a la información introducida por la última observación. Esto puede interpretarse como que el método tiene más memoria por lo que las nuevas iteraciones no cambian sustancialmente las estimaciones, con lo cual estas resultan menos ruidosas pero la convergencia se realentiza. Por el contrario, para valores menores de $\alpha$ se le da mayor peso a los estadísticos suficientes correspondientes a la última observación y menos a las estimanciones anteriores. Esto acelera la convergencia pero las trayectorias se hacen más ruidosas debido al error de muestreo.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{lor63_alphas.eps}
    \caption{Estimaciones de la media de la diagonal de $\v Q$ con OSS-EnKF (panel superior), IS-EnKF (panel medio) y IS-VMPF (panel inferior).}
    \label{fig:lor63_alphas}
\end{figure}

\subsubsection{Estimación de covarianzas}
En aplicaciones geofísicas es normal que las variables estén correlacionadas espacialmente. En estos sistemas es natural que el error de modelo también reproduzca estas correlaciones. Esto resulta en que la matriz $\v Q$ tenga una estructura con valores no nulos fuera de la diagonal. Para este conjunto de experimentos consideraremos el modelo Lorenz-96 \citep{Lorenz1996}, determinado por las siguientes ecuaciones diferenciales:
\begin{align}
    \frac{d X_n}{d t} = X_{n-1}(X_{n+1} - X_{n-2}) - X_n + F \hspace{1em} \forall n = 1, ..., N_x 
\end{align}
Tomaremos condiciones de frontera periódicas, es decir, $X_{-1} = X_{N_x-1}, X_0 = X_{N_x}, X_1 = X_{N_x+1}$. Este modelo busca emular el comportamiento de una variable atmosférica en un círculo de latitud con un forzado externo representado por $F$. Consideraremos, además de la varianza del error, representado por valores positivos en la diagonal de $\v Q$, covarianzas positivas e uniformes entre variables adyacentes. Esto significa que $\v Q_{i, (i+1)\%N_x} = \sigma_{ady}^2 > 0 \hspace{1em} \forall i = 1, ..., N_x$. Los valores en la diagonal también serán uniformes de manera que $\v Q_{i, i} = \sigma_{diag}^2 > 0 \hspace{1em} \forall i = 1, ..., N_x$. Para estimar esta matriz utilizamos las tres implementaciones del EM \textit{online} y también con 25 iteraciones del EM \textit{offline} en la implementación del Algoritmo \ref{algo:em_enks}. Notemos que la versión \textit{online} es una aproximación del \textit{offline} por lo que la segunda constituye una base de comparación razonable para la primera.

A pesar de que la matriz $\v Q$ tiene una estructura que admite una representación de sólo dos parámetros, las estimaciones producidas por cualquiera de los métodos son entrada por entrada (salvo simetría pues los estadísticos suficientes son simétricos). Para verificar que el comportamiento de las estimaciones en cada entrada es consistente mostramos en la figura \ref{fig:lor96_online_entrywise} las trayectorias correspondientes. Podemos observar que estas se agrupan correctamente alrededor de los valores de la matriz $\v Q$ original.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{lor96_online_entrywise.eps}
    \caption{}
    \label{fig:lor96_online_entrywise}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{lor96_online_batch.eps}
    \caption{}
    \label{fig:lor96_online_batch}
\end{figure}
En la figura \ref{fig:lor96_online_batch} se puede ver la distancia Frobenious de las estimaciones de todos los métodos. Los errores de las estimaciones en los métodos secuenciales se aproximan con velocidad similar entre ellos al error obtenido por el EM \textit{offline}. Además, para cada estimación de $\v Q$ se realizó un filtrado con el EnKF con $\v Q$ fijada en el valor de la estimación. Del resultado de estos filtrados computamos el RMSE de las varibles de estado y la log-verosimilitud obtenida. Se puede ver en la figura \ref{fig:lor96_online_batch} que la performance según estas métricas, son similares a las del EM \textit{batch}.

Finalmente, realizamos un experimento similar pero considerando que la matriz $\v Q$ varía lentamente en el tiempo de acuerdo a una función sigmoide. La versión \textit{batch} del EM produce una única estimación del parámetro para toda la ventana observacional. Por el otro lado los métodos secuenciales, al producir una estimación por cada observación son capaces de capturar cambios en el parámetro. Notemos sin embargo que las estimaciones, al tener ``memoria'' no pueden capturar cambios muy abruptos. En la figura \ref{fig:lor96_varyingQ} se observa que todos los métodos responden a los cambios en $\v Q$ aunque, especialmente para los valores en la diagonal se produce una subestimación respecto al valor real. Esto podría deberse a que el efecto de la memoria del método provoque que las estimaciones aún tengan una tendencia hacia los valores más tempranos y más pequeños de la ventana temporal. 
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{lor96_varyingQ.eps}
    \caption{}
    \label{fig:lor96_varyingQ}
\end{figure}

\clearpage

\subsubsection{Estimación conjunta de $\v Q$ y $\v R$} \

Hasta ahora nos hemos enfocado en la especificación del error de modelo puesto que es una fuente de incerteza de la cual, en la mayor parte de los casos, no tenemos forma de determinar debido a que suele provenir del desconocimiento del proceso subyacente. El error observacional por otro lado, muchas veces se puede aproximar pues conocemos mejor el proceso observacional. Sin embargo, como hemos visto en la sección \ref{sec:model_obs_error} la especificación de ambas incertezas es importante y de hecho existe interacción entre ambas cantidades. Por esto se hace importante estudiar la estimación conjunta de $\v Q$ y $\v R$. En este experimento lo hacemos tomando a ambas como matrices diagonales múltiplos de la identidad: $\v Q = \sigma_{\v Q}^2$ y $\v R = \sigma_{\v R}^2$. El modelo utilizado es el Lorenz-96 con 8 variables, todas observadas. Consideramos dos escenarios: en el primero tenemos errores observacionales y de modelo similares, $\sigma_{\v Q}^2 = 0.3$ y $\sigma_{\v R}^2 = 0.5$; mientras que en el segundo tomamos un error observacional mayor, $\sigma_{\v R}^2 = 1.5$. El efecto que se encuentra cuando $\v Q$ y $\v R$ son similares es que la verosimilitud tiene un máximo mejor definido. En la figura \ref{fig:lor96_contours} vemos los contornos de la verosimilitud en función de $\sigma_{\v Q}^2$ y $\sigma_{\v R}^2$ para ambos casos. El panel izquierdo corresponde al escenario de errores similares y se puede observar que el máximo es más definido que el escenario con errores disímiles del panel derecho. Además graficamos las trayectorias de las estimaciones para distintos valores iniciales. Se puede ver que cuando el máximo está mejor definido las estimaciones son más precisas. Finalmente notamos que los valores de la verosimilitud son menores en el caso de mayor error observacional, lo cual es esperable porque las observacions son menos precisas.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{lor96_contours.eps}
    \caption{}
    \label{fig:lor96_contours}
\end{figure}

\subsection{Discusión}

La metodología de EM \textit{online} que desarrollamos muestra resultados prometedores y da respuesta a algunos de los desafíos que típicamente se presentan en escenarios de asimilación de datos. La técnica permite evitar el uso de suavizadores sobre grandes ventanas temporales lo que la hace computacionalmente menos costosa que las versiones por lotes del EM y especialmente adecuada para contextos de asimilación de datos secuencial. Es importante notar que la performance puede depender de la tasa de aprendizaje utilizada. La técnica permite la estimación de varianzas pero también covarianzas en los errores de las variables de estado y adicionalmente detecta coambios temporales lentos en los parámetros estocásticos. No evaluamos el desempeño del método en espacios de alta dimensionalidad ya que en estos casos las mismas técnicas de asimilación pueden comenzar a tener peor rendimiento debido a que se dificulta la representación de distribuciones mediante muestras en este tipo de espacios.
