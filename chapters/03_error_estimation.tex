\chapter{Tratamiento de errores}

\section{Error observacional y de modelo}

Más allá de los desafíos y dificultades de implementación de las técnicas de asimilación de datos discutidas en el capítulo anterior, la performance de estas depende crucialmente de la especificación de el error de modelo y el observacional. Tanto la evolución de las variables de estado en el tiempo como el proceso observacional tienen fuentes de incerteza. De hecho, las metodologías de asimilación de datos hacen uso de nuestro conocimiento sobre estas incertidumbres para ponderar entre la información que brinda el pronóstico producido por el modelo y la observación. Veremos que una representación incorrecta de estos errores, y en particular de la razón entre estos, puede dar lugar a un exceso de confianza en los pronósticos o en las observaciones. Esto puede ocasionar que se degrade la calidad de las estimaciones de las distribuciones filtrantes y potencialmente que el filtro se desicronice de las trayectorias subyacentes sobre las que se intenta inferir.

Las variables de estado evolucionan en el tiempo mediante la aplicación del modelo $\mathcal{M}_t$ de la ecuación \ref{eq:transition} el cual se diseña para representar la dinámica del proceso subyacente. Por supuesto, estos modelos constituyen una representación imperfecta de la realidad que buscan describir. En lo que llamamos error de modelo, no sólo incluímos este error de representatividad sino también los provenientes de aproximaciones para simplificar el cómputo, errores numéricos y posiblemente la incerteza proveniente del desconocimiento de valores exactos de la parametrización de $\mathcal{M}_t$. Llamaremos laxamente $\v Q$ al error de modelo usando la notación en \ref{eq:kf_forward} que corresponde al caso común en que lo consideremos aditivo Gaussiano e insesgado. Por otro lado, el error observacional comprende al error de representatividad del operador $\mathcal{H}_t$, las imperfecciones en su especificación y las incertezas intrínsecas de los instrumentos de medición. Análogamente al error de modelo usaremos $\v R$ para referirnos al error observacional. Tenemos entonces que $\v Q$ y $\v R$ acumulan el error de diversas fuentes de incerteza y que además en ciertos casos, como el conocimiento incompleto sobre los fenómenos que modelamos, no disponemos de una cuantificación de estas incertidumbres.

% TODO: replicar ejemplo pierre

Como hemos visto en \ref{sec:enkf} en métodos basados en ensambles, estos tienen tendencia a colapsar debido a errores de muestreo. El error de modelo cobra una relevancia especial pues está asociada a la dispersión de las partículas del pronóstico y por lo tanto es importante especificarlo correctamente para un buen desempeño del sistema de asimilación. Por su parte, en los filtros de partículas, el error de modelo se relaciona a la incerteza de cada partícula. Muchos filtros de partículas modernos buscan mejorar el muestreo llevando a las partículas a regiones de alta verosimilitud como por ejemplo los filtros de partículas implícitos \citep{Chorin2009, Atkins2013, Zhu2016}, los filtros de flujos de partículas temperados \citep{Daum2009} o el filtro de partículas con mapeo variacional \citep{Pulido2019}. Estos suponen el conocimiento de $\v Q$ y por lo tanto se hace relevante poder acoplarlos con una metodología de estimación de dichos errores.

Se han desarrollado una gran cantidad de métodos para estimar estos errores. En \cite{Stroud2018} se apunta a maximizar la verosimilitud de las innovaciones (la diferencia entre la observación y el pronóstico mapeado al espacio observacional) utilizando inferencia Bayesiana. En otros trabajos se utilizan las covarianzas cruzadas entre innovaciones sucesivas para producir estimaciones de $\v Q$ y $\v R$ (Ver por ejemplo el trabajo seminal de \cite{Mehra1970} y una adaptación moderna basada en esta en \cite{Berry2013}). En el trabajo de \cite{Desroziers2005} se definen estadísticos de diagnóstico basados en las innovaciones que pueden ser utilizados para obtener coeficientes de inflación adaptativos \citep{Li2009}. Notemos que la inflación puede ser vista como un método de estimación del error de modelo puesto que da cuenta de la necesidad de ajustar la incertidumbre de los pronósticos. Otra aproximación al problema, sobre la que nos centraremos aquí, es la maximización de la verosimilitud total a través del algoritmo EM (\textit{expectation-maximization}, \cite{Dempster1977}). Este método fue acoplado con éxito al filtro de Kalman tradicional para estimar $\v Q$ y $\v R$ en \cite{Shumway1982} y con posteridad al filtro de Kalman por ensambles combinado con un suavizador de Kalman por ensambles (ver por ejemplo \cite{Dreano2017}). Un buen compendio de todas estas técnicas se puede encontrar en \cite{Tandeo2020}.

Dentro de toda la variedad de métodos para la estimación de errores observacionales y de modelo distinguimos los métodos \textit{offline} de los \textit{online}. Los primeros toman una ventana de observaciones $\v y_{1:T}$ y dan en base a estas una única estimación para $\v Q$ y $\v R$ para todos los tiempos $t = 1, ..., T$. El algoritmo EM es usualmente implementado de esta manera, utilizando un lote (\textit{batch}) de observaciones (tal es el caso en \cite{Dreano2017, Tandeo2015, Pulido2018}) y aplican el EnKF en combinación con el EnKS. Este procedimiento se adaptó para filtros de partículas en \cite{Lucini2021} sorteando la necesidad de utilizar un suavizador de partículas. En muchas aplicaciones no se utilizan suavizadores porque sólo hay interés en las distribuciones filtrantes y pronósticos y se implementan alternando predicción con análisis. Esto ahorra el costo computacional del suavizado y el almacentamiento de todas las estimaciones anteriores necesarias para el suavizador. En estos escenarios es impráctica o inviable la aplicación de métodos de estimación \textit{offline} y se hace necesario utilizar técnicas \textit{online} (también llamadas secuenciales o adaptativas). Estas producen estimaciones de $\v Q$ y $\v R$ de manera secuencial, es decir en cada ciclo de asimilación y utilizando la información de la observación que está siendo procesada (y no de todo el lote de observaciones de manera simultánea). En el trabajo de \cite{Neal1998} se propone una adaptación \textit{online} para el algoritmo EM y, en el contexto de modelos de Markov escondidos, podemos mencionar el algoritmo propuesto en \cite{Cappe2009} que implementa ideas de EM secuencial acoplados a filtros de partículas y las implementaciones de \cite{Andrieu2003} que utilizan pseudo-verosimilitudes basadas en mini-lotes de datos. También es necesario mencionar que existen implementaciones \textit{online} para estimación de errores que no están basadas en EM como por ejemplo la que se puede encontrar en \cite{Berry2013}.

En el trabajo del cual forma parte esta tesis, desarrollamos un nuevo método \textit{online} de estimación de error de modelo y observacional basado en EM compatible con filtros de partículas y con EnKFs. La técnica combina las ideas del \textit{batch} EM en la versón de \cite{Dreano2017} con las ideas expuestas por \cite{Cappe2009} y \cite{Andrieu2003} y el resultado está publicado en \cite{Cocucci2021}. Para dar una derivación del método desarrollaremos el algoritmo EM tradicional por lotes en \ref{sec:batchEM} y luego haremos la deducción teórica con la que podemos hacer la adaptación secuencial en \ref{sec:onlineEM}. 

\section{Estado aumentado}

En la sección anterior se dicutió la relevancia de utilizar estimaciones apropiadas de los errores involucrados. Los parámetros que codifican a estas incertezas suelen ser llamados parámetros ``estocásticos''. Por otro lado, distinguimos a los parámetros específicos al modelo transicional $\mathcal{M}_t$ los cuales suelen ser llamados parámetros ``determinísticos'' ya que usualmente son cantidades interpretables como parte de la dinámica subyacente de las variables de estado $\v x_t$. Es normal que no se cuente con un parametrización precisa del modelo de transición y por lo tanto se deban tomar recaudos. En parte, y como fue mencionado en la sección anterior, se puede dar cuenta de la imperfección en la parametrización de $\v \mathcal{M}_t$ a través del error de modelo y delegar a la estimación de este las incertezas de los parámetros determinísticos. Sin embargo, con la técnica conocida como ``estado aumentado'', es posible estimarlos individualmente y de esta manera calibrar el modelo. Esta consiste en incorporar los parámetros a las variables de estado e interpretarlas como cantidades no observadas del sistema. Si llamamos $\gv\theta_t$ a los parámetros que queremos estimar, construimos entonces el estado aumentado $\tilde{\v x}_t = (\v x_t, \gv \theta_t)$ (notemos la subindexación $t$ que incluímos porque este método admite que los parámetros varíen en el tiempo). Para poder implementar esta idea es necesario extender $\v H_t$ para que interprete a los parámetros como variables no observadas y a $\v \mathcal{M}_t$ para que actúe sobre estos.

Las técnicas de asimilación de datos pueden inferir sobre variables no observadas ya que la asimilación captura las correlaciones entre estas y las observaciones. En el caso de que esta correlación sea muy débil, el análisis será conservador respecto a la variable no observada que permanecerá cerca del pronóstico. Por lo tanto, este comportamiento se replica para los parámetros en estado aumentado y, en el caso que las correlaciones mencionadas sean los suficientemente fuertes, se podrán obtener estimaciones para los parámetros. Además, como estas estimaciones son secuenciales y siguen la lógica ``pronóstico-análisis'' como el resto de las variables de estado, es posible estimar parámetros con variación temporal dando lugar a un sistema que se auto-calibra \citep{Ruiz2013}. Sin embargo, hay que mencionar que, como los parámetros son utilizados en el modelo para el paso de tiempo subsiguiente, si los cambios en el parámetro son muy bruscos el sistema tardará en capturarlos, de manera que la adaptividad del método está sujeta a que las variaciones temporales de los parámetros sean lo suficientemente lentas como para que el sistema pueda asimilarlas. 

Para la extensión de $\v \mathcal{M}_t$ sobre los parámetros es común considerar que actúa como la identidad sobre los parámetros. Esto significa que si $\gv \theta \in \gv\Theta$ entonces $\v \mathcal{M}_t |_{\gv\Theta} (\gv \theta) = \gv \theta$. Sin embargo también habitual incorporar una caminata aleatoria Gaussiana $\v \mathcal{M}_t |_{\gv\Theta} (\gv \theta) = \gv \theta + \gv\epsilon_t$ con $\gv\epsilon_t \sim \mathcal{N}(\v 0, \gv\Sigma_{\gv\epsilon})$. Esto ayuda a que el pronóstico de los parámetros consiga una mejor exploración del espacio paramétrico. Por supuesto, se puede modelar una dinámica para la evolución de los parámetros si fuera necesario. En el caso que se utilice esta estrategia $\gv\Sigma_{\gv\epsilon}$ cuantifica la magnitud de los pasos de la caminata aleatoria y se constituye como un hiperparámetro que se puede calibrar para mejorar la performance del sistema de asimilación. 

La técnica de estado aumentado suele ser adecuada para muchos parámetros físicos y por lo tanto es tentador utilizarla para el tratamiento de los parámetros estocásticos. Sin embargo, debido a la falta de correlación entre la información observacional y los parámetros estocásticos, el método no produce buenos resultados. En \cite{Delsole2010} se puede encontrar una definición algo más precisa de parámetros determinísticos y estocásticos así como una justificación más completa de por qué aumentar el estado con parámetros estocásticos no puede dar buenas estimaciones.

\section{Algoritmo EM}

El algoritmo EM se utiliza para obtener estimadores de máxima verosimilitud en sistemas parcialmente observados. Es en realidad una metodología general y no una solución \textit{off-the-shelf}. Su aplicación más conocida es en el contexto de aprendizaje no supervisado para hacer \textit{clustering} modelando el problema con una mezcla de Gaussianas \citep{Bishop2006} pero tiene una gran diversidad de utilidades. Comenzaremos dando su forma general, luego su aplicación en lotes para estimación de matrices de covarianzas en \textit{state space models} con error aditivo Gaussiano y finalmente su adaptación \textit{online}.

El algoritmo EM en un modelo probabilístico en el que contamos con una variable observada $\v Y$, variables no observadas $\v X$ y un parámetro $\gv\theta$ el cual describe a la probbilidad conjunta $p(\v X,  \v Y; \gv\theta)$. El objetivo es utilizar datos $\v Y$ para estimar el parámetro $\gv\theta$ mediante la maximización de la verosimilitud $p(\v Y; \gv\theta)$ o equivalentemente, de su logaritmo. Si dotamos a las variables no observadas de una distribución \textit{a priori} $q(\v X)$ podemos obtener la expresión:

\begin{align}
    \log p(\v Y; \gv\theta) &=  \log \int p(\v X, \v Y; \gv\theta) d\v X \\
    &=  \underbrace{\int q(\v X) \log \frac{q(\v X)}{p(\v X | \v Y; \gv\theta)} d\v X}_{KL(\int q(\v X) \rVert p(\v X | \v Y; \gv\theta))} + \underbrace{\int q(\v X) \log \frac{p(\v X, \v Y; \gv\theta)}{q(\v X)} d\v X}_{\mathcal{L}(q, \gv\theta)} \label{eq:elbo_KL}
\end{align}
donde $KL$ es la divergencia de Kullback-Leibler y $\mathcal{L}$ es llamada ELBO (\textit{evidence lower bound}). Es común interpretar a $KL$ como una ``distancia'' entre probabilidades y de hecho, cumple que $KL(q \rVert p) \geq 0$ y se anula sí y sólo si $p = q$ en casi todo punto. Al ser $KL$ mayor o igual a 0, esto significa que $\log p(\v Y; \gv\theta) \geq \mathcal{L}(q, \gv\theta)$, es decir que la ELBO es una cota inferior de la log-verosimilitud.  

El algoritmo EM provee estimaciones $\gv\theta_0, \gv\theta_1, ...$ tales que $\log p(\v Y; \gv\theta_{t+1}) \geq \log p(\v Y; \gv\theta_t)$ que convergen a un máximo local de la verosimilitud \citep{Wu1983}. Como dado un $q$ fijo, la $\mathcal{L}(q,\gv\theta)$ es una cota inferior de $\log p(\v Y; \gv\theta)$ para todo $\gv\theta$, entonces la idea es maximizar $\mathcal{L}(q,\gv\theta)$ primero respecto a $q$ y luego respecto a $\gv\theta$. Supongamos que ya contamos con la estimación de la $t$-ésima iteración, $\gv\theta_t$. Si queremos obtener $q = \argmax\limits_{q}\mathcal{L}(q,\gv\theta_t)$, notemos que la igualdad \ref{eq:elbo_KL} se satisface para todo $q$ por lo que debemos elegir el valor que anule a la divergencia de Kullback-Leibler, es decir $q = p(\v X | \v Y; \gv\theta_t)$. Luego, dejamos fijo $q$ y elegimos $\theta_{t+1}$ tal que $\mathcal{L}(q,\gv\theta_{t+1}) \geq \mathcal{L}(q,\gv\theta_t)$. De esta manera obtendremos que 
\begin{align*}
    \log p(\v Y; \gv\theta_t) &= \mathcal{L}(p(\v X | \v Y; \gv\theta_t), \gv\theta_t) + \overbrace{KL(p(\v X | \v Y; \gv\theta_t) \rVert p(\v X | \v Y; \gv\theta_t))}^{0} \\
    &= \mathcal{L}(p(\v X | \v Y; \gv\theta_t), \gv\theta_t) \\
    &\leq \mathcal{L}(p(\v X | \v Y; \gv\theta_t), \gv\theta_{t+1}) \\
    % &\leq \mathcal{L}(p(\v X | \v Y; \gv\theta_t), \gv\theta_{t+1}) + \overbrace{KL(p(\v X | \v Y; \gv\theta_t) \rVert p(\v X | \v Y; \gv\theta_{t+1}))}^{\geq 0} \\
    &\leq \log p(\v Y; \gv\theta_{t+1})
\end{align*}
y por lo tanto que las estimaciones producidas incrementan la verosimilitud.

Notemos además que una vez elegido $q$ tal que anule a la divergencia de Kullback-Liebler en la iteración $t$ obtenemos que:
\begin{align*}
    \mathcal{L}(p(\v X | \v Y; \gv\theta_t), \gv\theta) &= \int p(\v X | \v Y; \gv\theta_t) \log \frac{p(\v X, \v Y; \gv\theta)}{p(\v X | \v Y; \gv\theta_t)} d\v X \\
    &= \int p(\v X | \v Y; \gv\theta_t) \log p(\v X, \v Y; \gv\theta) d\v X - \int p(\v X | \v Y; \gv\theta_t) \log p(\v X | \v Y; \gv\theta_t) d\v X \\
    &\propto_{\theta} \int p(\v X | \v Y; \gv\theta_t) \log p(\v X, \v Y; \gv\theta) d\v X \\
    &\dot{=} E_{\gv\theta_t}[\log p(\v X, \v Y; \gv\theta)| \v Y]
\end{align*}
es decir que la ELBO se puede expresar como una esperanza condicional una vez que elegimos $q$ que maximiza a $\mathcal{L}$. Debido a esto, la maximización sobre $q$ recibe el nombre de \textit{E-step}. Por otra parte el \textit{M-step} corresponde a la maximización sobre $\gv\theta$. El procedimiento admite entonces la caracterización que presentada en \ref{algo:general_EM}.

\begin{algorithm}[H]\label{algo:general_EM}

    Elegir valor inicial $\gv\theta_0$:\

    \For{$t=0, 1, ..., $}{
        E-step: \
            Computar $\mathcal{Q}(\gv\theta, \gv\theta_t) = E_{\gv\theta_t}[\log p(\v X, \v Y; \gv\theta)| \v Y]$

        M-step: \
            $\gv\theta_{t+1} = \argmax\limits_{\gv \theta} \mathcal{Q}(\gv\theta, \gv\theta_t)$
    }
\caption{EM general}
\end{algorithm}


\subsection{Batch EM} \label{sec:batchEM}
\subsection{Online EM} \label{sec:onlineEM}
